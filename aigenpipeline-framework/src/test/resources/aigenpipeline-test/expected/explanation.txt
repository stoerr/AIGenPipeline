Response to:
{
  "model": "gpt-4-turbo-preview",
  "messages": [
    {
      "role": "system",
      "content": "Follow the users instructions to the letter.\n"
    },
    {
      "role": "user",
      "content": "Retrieve the content of the input file src/test/resources/aigenpipeline-test/input.txt"
    },
    {
      "role": "assistant",
      "content": "This is a test input file for AIGenerationTask."
    },
    {
      "role": "user",
      "content": "This is a test prompt for AIGenerationTask."
    },
    {
      "role": "assistant",
      "content": "// \n\nResponse to:\n{\n  \"model\": \"gpt-4-turbo-preview\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Follow the users instructions to the letter.\\n\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Retrieve the content of the input file src/test/resources/aigenpipeline-test/input.txt\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"This is a test input file for AIGenerationTask.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"This is a test prompt for AIGenerationTask.\"\n    }\n  ],\n  \"temperature\": 0.0,\n  \"max_tokens\": 1000\n}\n"
    },
    {
      "role": "user",
      "content": "Why oh why oh why?"
    }
  ],
  "temperature": 0.0,
  "max_tokens": 1000
}
